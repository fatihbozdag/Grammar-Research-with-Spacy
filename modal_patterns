import spacy
import pandas as pd
import re
from typing import List, Tuple

def load_data() -> Tuple[pd.DataFrame, pd.DataFrame]:
    meta = pd.read_csv('F:/learner Corpora/metadata_with_text.csv')
    text = pd.read_csv('F:/Learner Corpora/text_only.csv')

    pattern = r'ICLE\-\w+\-\w+\-\d+\.\d+'
    text['text_field'] = text['text_field'].apply(lambda x: re.sub(pattern, '', x).replace('\n', ''))

    return meta, text

def process_texts(meta: pd.DataFrame, text: pd.DataFrame) -> List[Tuple[str, dict]]:
    meta_x = meta.to_dict('records')
    text_only = text['text_field'].values.tolist()
    return list(zip(text_only, meta_x))

def process_modal_pattern(meta_text: List[Tuple[str, dict]], pattern_function) -> pd.DataFrame:
    modal_pattern = []

    for doc, context in nlp.pipe(meta_text, as_tuples=True):
        modal_pattern.extend(pattern_function(doc, context))

    return pd.DataFrame(modal_pattern)

def pattern1_function(doc, context):
    results = []
    for a in doc:
        if a.dep_ == 'aux' and a.tag_ == 'MD' and a.head.tag_ == 'VB':
            for b in a.head.children:
                if b.dep_ == 'nsubj':
                    result = {'Docid_field': context['docid_field'],
                              'Subject': b.text,
                              'Subject_Pos': b.pos_,
                              'Modal': a.text,
                              'Verb': a.head.text,
                              'Sent': a.sent}
                    results.append(result)
    return results
    
 def pattern2_function(doc, context):
   results = []
   for token in doc:
       if token.dep_ == "aux" and token.tag_ == "MD" and token.head.tag_ == "VBG":
           for child in token.head.children:
               if child.dep_ == "nsubj":
                   results.append((context["docid_field"], child.text, child.pos_, token.text, token.head.text, token.sent))
   return results


def pattern3_function(doc, context):
    results = []
    for token in doc:
        if token.dep_ == "aux" and token.tag_ == "MD" and token.head.tag_ == "VBN":
            for child in token.head.children:
                if child.dep_ == "nsubj":
                    results.append((context["docid_field"], child.text, child.pos_, token.text, token.head.text, token.sent))
    return results


def pattern4_function(doc, context):
    results = []
    for token in doc:
        if token.dep_ == "ROOT" and token.tag_ == "VBN":
            for child in token.children:
                if child.dep_ == "aux" and child.tag_ == "MD":
                    for c in token.children:
                        if c.dep_ == "auxpass" and c.tag_ == "VB":
                            for d in token.children:
                                if d.dep_ == "nsubjpass":
                                    results.append((context["docid_field"], d.text, d.pos_, child.text, token.text, token.sent))
    return results


def pattern5_function(doc, context):
    results = []
    for token in doc:
        if token.dep_ == "ROOT" and token.tag_ == "VBN":
            for child in token.children:
                if child.dep_ == "aux" and child.tag_ == "MD":
                    for c in token.children:
                        if c.dep_ == "auxpass" and c.tag_ == "VBN":
                            for d in token.children:
                                if d.dep_ == "nsubjpass":
                                    results.append((context["docid_field"], d.text, d.pos_, child.text, token.text, token.sent))
    return results


# Define other pattern functions (pattern2_function, pattern3_function, pattern4_function, pattern5_function) here.

def main():
    meta, text = load_data()
    icle = process_texts(meta, text)
    
    pattern1_df = process_modal_pattern(icle, pattern1_function)
    pattern2_df = process_modal_pattern(icle, pattern2_function)
    pattern3_df = process_modal_pattern(icle, pattern3_function)
    pattern4_df = process_modal_pattern(icle, pattern4_function)
    pattern5_df = process_modal_pattern(icle, pattern5_function)

    combined_df = pd.concat([pattern1_df, pattern2_df, pattern3_df, pattern4_df, pattern5_df], ignore_index=True)
    print(combined_df)

if __name__ == "__main__":
    main()

### Regression analysis code starts here ###

import arviz as az
import bambi as bmb
import matplotlib.pyplot as plt

plt.show(block=True)
plt.interactive(False)
import numpy as np
import pandas as pd
import seaborn as sns
import pymc as pm
import pymc.sampling_jax
import numpyro
import pickle

from matplotlib.lines import Line2D

print(f"Running on PyMC v{pm._version_}")

patterns = pd.read_csv('allpatterns.csv', encoding='utf-8') ### make sure you import your own csv file###

common_prior = bmb.Prior("Normal", mu=0, sigma = 1)
priors = {"Subject_Pos": common_prior, "Native_language": common_prior, "Modal_C":common_prior,"Verb_C":common_prior, "Pattern_Type": common_prior}

patterns_model = bmb.Model("Frequency ~ Subject_Pos + Native_language + Modal_C + Verb_C + Pattern_Type", data=patterns, priors=priors)

results = patterns_model.fit(
    target_accept=0.95,
    draws=2000,
    tune=1000,
    return_inferencedata=True,
)

az.plot_trace(results)
plt.show()

az.summary(results, round_to=2)

# Save the model
with open("patterns_model.pkl", "wb") as f:
    pickle.dump(patterns_model, f)

# Load the model
with open("patterns_model.pkl", "rb") as f:
    loaded_patterns_model = pickle.load(f)

