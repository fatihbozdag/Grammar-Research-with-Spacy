###First import all the packages

import pandas as pd
import spacy
import math
import re as re
nlp = spacy.load('en_core_web_trf') ###note that trf model requires GPU, or else you can import en_core_web_lg model###
nlp.max_length = 150000000000000

###simple re to clean html tags from corpus data###
def remove_tags(string):
    result = re.sub('<[^<]+?>', '', string)
    return result
    
###Create list from csv files and merge them as list of list for spacy parsing with metadata

### Note that ICLE International Corpus of Learner English is copyrighted data, so I cannot share it ###
icle = [] 
meta = pd.read_csv('F:/learner Corpora/metadata_with_text.csv') #icle corpus metada files from local computer
text = pd.read_csv('F:/Learner Corpora/text_only.csv') #icle corpus text files from local computer

text['text_field'] = text['text_field'].apply(lambda ch : remove_tags(ch)) #remove html link included in the corpus text files

###this is required for spacy_tuples to get context data from metadata. Or else you can simply proceed with Pandas Data Frame.###
meta_x = meta.to_dict('records')
text_only = text['text_field'].values.tolist()
icle = list(zip(text_only, meta_x))

### I created list for each item since for further statistical analysis included regression analysis ####

dative_sents = []
nsubj = []
nsubj_pos = []
root = []
root_pos = []
dative = []
dative_pos = []
direct_obj = []
direct_obj_pos = []
pre_obj = []
pre_obj_pos = []
sents = []
nsubj_pre = []
nsubj_pre_pos = []
root_pre = []
root_pre_pos = []
dative_pre = []
dative_pre_pos = []
direct_obj_pre = []
direct_obj_pre_pos = []
sent_pre = []
dative_sentences_pre = []
dative_sentences = []
native_language = []
native_language_pre = []
length_direct_obj = []
length_dative = []
length_pre_obj = []
length_pre_direct_obj = []
doc_id = []
doc_id_pre = []

### In some cases, spacy tags relative/adverbial clauses as pobj/dobj, this is a black to prevent Spacy incorrect parsing ###
relative_pron_list = ['which', 'what', 'who', 'that', " "]
pos_list = ['SPACE', 'X', 'SCON'] ### data is not always clean and not all sentences are perfectly accurate. This is the black list to eliminate sentences with NULL input.

for doc, context in nlp.pipe(icle, as_tuples =True): ###Initial loop for parsing sentences with double object dative 'I gave him some money'###
      for d in doc:
          if d.dep_ == "dative" and d.pos_ != 'ADP' and d.head.pos_ == "VERB" and d.lemma_ not in relative_pron_list:
              for n in d.head.children:
                       if n.dep_ == "nsubj" and n.pos_ != 'SPACE' and n.lemma_ not in relative_pron_list:
                          for x in d.head.children:
                               if x.dep_ == "dobj" and x.pos_ != 'SPACE' and x.lemma_ not in relative_pron_list:
                                    
                                        dative.append(d.text)
                                        dative_pos.append(d.pos_)
                                        length_dative.append(math.log10(len(d.text))) ### log-lenght in character of the dative/recipient###
                                        root.append(d.head.lemma_)
                                        nsubj.append(n.text)
                                        nsubj_pos.append(n.pos_)
                                        direct_obj.append(x.text)
                                        direct_obj_pos.append(x.pos_)
                                        length_direct_obj.append(math.log10(len(x.text))) ### log-length in character of theme###
                                        dative_sentences.append(d.sent)
                                        native_language.append(context['Native_language'])
                                        doc_id.append(context['docid_field'])
                                        
for doc, context in nlp.pipe(icle, as_tuples =True): ###Second loop for parsing double object sentences ' I gave some money to him'###
    for b in doc:
        if b.dep_ == "dative" and b.pos_ == "ADP" and b.head.pos_ == "VERB":
            for m in b.head.children:
                if m.dep_ == "nsubj" and m.pos_ != 'SPACE' and m.lemma_ not in relative_pron_list:
                    for k in b.head.children:
                        if k.dep_ == "dobj" and k.pos_ != 'SPACE' and k.lemma_ not in relative_pron_list:
                         for l in b.children:
                            if l.dep_ == "pobj" and l.pos_ != 'SPACE' and l.lemma_ not in relative_pron_list:
                                    
                                        dative_pre.append(b.text)
                                        dative_pre_pos.append(b.pos_)
                                        root_pre.append(b.head.lemma_)
                                        nsubj_pre.append(m.text)
                                        nsubj_pre_pos.append(m.pos_)
                                        direct_obj_pre.append(k.text)
                                        direct_obj_pre_pos.append(k.pos_)
                                        length_pre_direct_obj.append(math.log10(len(k.text))) ### log-length in character of theme###
                                        pre_obj.append(l.text)
                                        pre_obj_pos.append(l.pos_)
                                        length_pre_obj.append(math.log10(len(l.text))) ### log-lenght in character of the dative/recipient###
                                        dative_sentences_pre.append(b.sent)
                                        native_language_pre.append(context['Native_language'])
                                        doc_id_pre.append(context['docid_field'])
                                        
dative_without_pre = pd.DataFrame({"Native_Language": native_language, 
                                          "Doc_id": doc_id, "Nsubj" : nsubj, "Agent_Pos": nsubj_pos, "Verb" : root,
                                          "Recipient" : dative, "Recipient_Pos" : dative_pos,"Recipient_length": length_dative, 
                                           "Theme" :  direct_obj, "Theme_Pos": direct_obj_pos, "Theme_length": length_direct_obj, "Dative_Sentences" : dative_sentences})
                                           
dative_with_pre = pd.DataFrame({"Native_Language": native_language_pre,
                                            "Doc_id": doc_id_pre, "Agent" : nsubj_pre, "Agent_Pos": nsubj_pre_pos, "Verb" : root_pre, 
                                             "Theme" : direct_obj_pre, "Theme_Pos": direct_obj_pre_pos, "Theme_length": length_pre_direct_obj, 
                                             "Dative" : dative_pre, "Recipient": pre_obj, "Recipient_Pos": pre_obj_pos,"Recipient_length": length_pre_obj, "Dative_Sentences" : dative_sentences_pre})
