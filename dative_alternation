###Create list from csv files and merge them as list of list for spacy parsing with metadata

import pandas as pd
import spacy
import texthero as hero
from texthero import preprocessing
import math
import re as re
nlp = spacy.load('en_core_web_lg')
nlp.max_length = 150000000000000

custom_pipeline = [preprocessing.fillna,
                   preprocessing.remove_digits,
                   preprocessing.remove_diacritics,
                   preprocessing.remove_html_tags]

def remove_tags(string):
    result = re.sub('<[^<]+?>', '', string)
    return result
    
icle = []
meta = pd.read_csv('F:/learner Corpora/metadata_with_text.csv') #icle corpus metada files from local
text = pd.read_csv('F:/Learner Corpora/text_only.csv') #icle corpus text files from local

text['text_field'] = text['text_field'].apply(lambda ch : remove_tags(ch)) #remove html link included in the corpus text files
text['text_field'] = hero.clean(text['text_field'], custom_pipeline) #remove extra characters from text files

meta_x = meta.to_dict('records')
text_only = text['text_field'].values.tolist()
icle = list(zip(text_only, meta_x))
dative_sents = []
nsubj = []
nsubj_pos = []
root = []
root_pos = []
dative = []
dative_pos = []
direct_obj = []
direct_obj_pos = []
pre_obj = []
pre_obj_pos = []
sents = []
nsubj_pre = []
nsubj_pre_pos = []
root_pre = []
root_pre_pos = []
dative_pre = []
dative_pre_pos = []
direct_obj_pre = []
direct_obj_pre_pos = []
sent_pre = []
dative_sentences_pre = []
dative_sentences = []
native_language = []
native_language_pre = []
length_direct_obj = []
length_dative = []
length_pre_obj = []
length_pre_direct_obj = []
doc_id = []
doc_id_pre = []
relative_pron_list = ['which', 'what', 'who', 'that', " "]
pos_list = ['SPACE', 'X', 'SCON']
for doc, context in nlp.pipe(icle, as_tuples =True):
      for d in doc:
          if d.dep_ == "dative" and d.pos_ != 'ADP' and d.head.pos_ == "VERB" and d.lemma_ not in relative_pron_list:
              for n in d.head.children:
                       if n.dep_ == "nsubj" and n.pos_ != 'SPACE' and n.lemma_ not in relative_pron_list:
                          for x in d.head.children:
                               if x.dep_ == "dobj" and x.pos_ != 'SPACE' and x.lemma_ not in relative_pron_list:
                                    
                                        dative.append(d.text)
                                        dative_pos.append(d.pos_)
                                        length_dative.append(math.log10(len(d.text)))
                                        root.append(d.head.lemma_)
                                        nsubj.append(n.text)
                                        nsubj_pos.append(n.pos_)
                                        direct_obj.append(x.text)
                                        direct_obj_pos.append(x.pos_)
                                        length_direct_obj.append(math.log10(len(x.text)))
                                        dative_sentences.append(d.sent)
                                        native_language.append(context['Native_language'])
                                        doc_id.append(context['docid_field'])
                                        
for doc, context in nlp.pipe(icle, as_tuples =True):
    for b in doc:
        if b.dep_ == "dative" and b.pos_ == "ADP" and b.head.pos_ == "VERB":
            for m in b.head.children:
                if m.dep_ == "nsubj" and m.pos_ != 'SPACE' and m.lemma_ not in relative_pron_list:
                    for k in b.head.children:
                        if k.dep_ == "dobj" and k.pos_ != 'SPACE' and k.lemma_ not in relative_pron_list:
                         for l in b.children:
                            if l.dep_ == "pobj" and l.pos_ != 'SPACE' and l.lemma_ not in relative_pron_list:
                                    
                                        dative_pre.append(b.text)
                                        dative_pre_pos.append(b.pos_)
                                        root_pre.append(b.head.lemma_)
                                        nsubj_pre.append(m.text)
                                        nsubj_pre_pos.append(m.pos_)
                                        direct_obj_pre.append(k.text)
                                        direct_obj_pre_pos.append(k.pos_)
                                        length_pre_direct_obj.append(math.log10(len(k.text)))
                                        pre_obj.append(l.text)
                                        pre_obj_pos.append(l.pos_)
                                        length_pre_obj.append(math.log10(len(l.text)))
                                        dative_sentences_pre.append(b.sent)
                                        native_language_pre.append(context['Native_language'])
                                        doc_id_pre.append(context['docid_field'])
dative_without_pre = pd.DataFrame({"Native_Language": native_language, "Doc_id": doc_id, "Nsubj" : nsubj, "Agent_Pos": nsubj_pos, "Verb" : root, "Recipient" : dative, "Recipient_Pos" : dative_pos,"Recipient_length": length_dative, "Theme" :  direct_obj, "Theme_Pos": direct_obj_pos, "Theme_length": length_direct_obj, "Dative_Sentences" : dative_sentences})
dative_with_pre = pd.DataFrame({"Native_Language": native_language_pre, "Doc_id": doc_id_pre, "Agent" : nsubj_pre, "Agent_Pos": nsubj_pre_pos, "Verb" : root_pre, "Theme" : direct_obj_pre, "Theme_Pos": direct_obj_pre_pos, "Theme_length": length_pre_direct_obj, "Dative" : dative_pre, "Recipient": pre_obj, "Recipient_Pos": pre_obj_pos,"Recipient_length": length_pre_obj, "Dative_Sentences" : dative_sentences_pre})
